package com.apollographql.apollo3.compiler

import com.apollographql.apollo3.ast.GQLFragmentDefinition
import com.apollographql.apollo3.ast.Schema
import com.apollographql.apollo3.ast.parseAsGQLDocument
import com.apollographql.apollo3.ast.toSchema
import com.apollographql.apollo3.ast.toUtf8
import com.apollographql.apollo3.compiler.codegen.ResolverInfo
import com.squareup.moshi.FromJson
import com.squareup.moshi.JsonAdapter
import com.squareup.moshi.JsonClass
import com.squareup.moshi.JsonReader
import com.squareup.moshi.JsonWriter
import com.squareup.moshi.Moshi
import com.squareup.moshi.ToJson
import okio.buffer
import okio.sink
import okio.source
import java.io.File

/**
 * metadata generated by a previous run of [ApolloCompiler]. The schema and fragments are stored as GraphQL document strings. This
 * slightly unfortunate because that means we will parse them twice but there isn't many alternatives as validation and IR-building takes
 * GQLDocuments as inputs. A future version could serialize GQLNode as json in order to keep the SourceLocation attributes and display
 * better error messages
 */
@JsonClass(generateAdapter = true)
data class ApolloMetadata(
    /**
     * Only non-null for the root module
     */
    val commonMetadata: CommonMetadata?,
    val compilerMetadata: CompilerMetadata,
    val moduleName: String
) {
  companion object {

    /**
     * A JsonAdapter that will use SDL to serialize Schema and GQLFragmentDefinition
     */
    private val adapter by lazy {
      val gqlFragmentJsonAdapter = object : JsonAdapter<GQLFragmentDefinition>() {
        override fun fromJson(reader: JsonReader): GQLFragmentDefinition {
          val string = reader.nextString()
          return string.buffer().parseAsGQLDocument().valueAssertNoErrors().definitions.first() as GQLFragmentDefinition
        }

        override fun toJson(writer: JsonWriter, fragmentDefinition: GQLFragmentDefinition?) {
          writer.value(fragmentDefinition!!.toUtf8())
        }
      }

      Moshi.Builder()
          .add(SchemaAdapter())
          .add(GQLFragmentDefinition::class.java, gqlFragmentJsonAdapter.nonNull())
          .build()
          .adapter(ApolloMetadata::class.java)
    }

    fun readFrom(file: File) = adapter.fromJson(file.source().buffer()) ?: error("bad metadata at ${file.absolutePath}")
  }

  fun writeTo(file: File) {
    file.parentFile.mkdirs()
    file.sink().buffer().use {
      adapter.toJson(it, this)
    }
  }
}

private class SchemaAdapter {
  @ToJson fun toJson(schema: Schema): Map<String, Any> {
    return schema.toMap()
  }

  @FromJson fun fromJson(map: Map<String, Any>): Schema {
    return Schema.fromMap(map)
  }
}

/**
 * Options that must be common to all modules
 */
@JsonClass(generateAdapter = true)
data class CommonMetadata(
    val schema: Schema,
    val schemaPackageName: String,
    val pluginVersion: String,
    val codegenModels: String,
    /**
     * Scalar mapping needed for scalars' target types and Adapter initializers
     */
    val scalarMapping: Map<String, ScalarInfo>,
)

/**
 * Compilation unit specific metadata that is specific to a given invocation of the compiler
 */
@JsonClass(generateAdapter = true)
data class CompilerMetadata(
    /**
     * The fragments needed:
     * - to validate the operations
     * - to embed the fragment source in the query document
     * - to lookup the super interfaces when generating response-based models
     */
    val fragments: List<GQLFragmentDefinition>,
    /**
     * resolver info used by the codegen to lookup already existing ClassNames
     */
    val resolverInfo: ResolverInfo,
)
